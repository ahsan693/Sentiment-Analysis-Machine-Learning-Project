{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf8922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.35.2 datasets tokenizers tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05fafd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c6e73355614f11bb4458a47cc90308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  16%|#6        | 52.4M/320M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d70611b14f471997462139b3310770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c085cd676fc4c6cafe26ea05e56410d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9971315860748291}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "# Run it on some sample text\n",
    "result = classifier(\"I love using Hugging Face transformers!\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82c3a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-win_amd64.whl.metadata (883 bytes)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.7 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.6/2.7 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db8242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e888cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love this product! It's amazing.\n",
      "Label: POSITIVE, Confidence: 0.9999\n",
      "\n",
      "Text: This is the worst experience I've ever had.\n",
      "Label: NEGATIVE, Confidence: 0.9998\n",
      "\n",
      "Text: It’s okay, not great but not bad either.\n",
      "Label: POSITIVE, Confidence: 0.9986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Sample text(s) for analysis\n",
    "texts = [\n",
    "    \"I love this product! It's amazing.\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"It’s okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiment for each text\n",
    "for text in texts:\n",
    "    result = classifier(text)[0]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Label: {result['label']}, Confidence: {result['score']:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1f748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO=0.95, NOx=0.16, NO2=0.51 => Health Advisory: Unhealthy (0.86)\n",
      "CO=0.95, NOx=0.13, NO2=0.45 => Health Advisory: Unhealthy (0.86)\n",
      "CO=0.96, NOx=0.30, NO2=0.58 => Health Advisory: Unhealthy (0.87)\n",
      "CO=0.96, NOx=0.22, NO2=0.00 => Health Advisory: Unhealthy (0.87)\n",
      "CO=0.98, NOx=0.52, NO2=0.73 => Health Advisory: Unhealthy (0.87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2092\\35653887.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(lambda x: str(x).strip().replace('\\t', '').replace(' ', '') if pd.notnull(x) else x)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc67725d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
